{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\dzhal\\Anaconda3\\envs\\neural_network\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\dzhal\\Anaconda3\\envs\\neural_network\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\dzhal\\Anaconda3\\envs\\neural_network\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\dzhal\\Anaconda3\\envs\\neural_network\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\dzhal\\Anaconda3\\envs\\neural_network\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\dzhal\\Anaconda3\\envs\\neural_network\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from glob import glob \n",
    "from skimage.io import imread\n",
    "import gc\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from DataGenerator import CreateData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzhal\\informtelecs\\DataGenerator.py:151: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(15, 10))  # think about scale\n",
      "C:\\Users\\dzhal\\informtelecs\\DataGenerator.py:85: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(15, 10))\n",
      "C:\\Users\\dzhal\\informtelecs\\DataGenerator.py:82: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  y = 1/koef * np.array(x) if i == 0 else koef * np.array(x)\n",
      "C:\\Users\\dzhal\\informtelecs\\DataGenerator.py:106: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(15, 10))\n",
      "C:\\Users\\dzhal\\informtelecs\\DataGenerator.py:123: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(15, 10))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DataGenerator.CreateData at 0x2e9351e26d8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createData = CreateData()\n",
    "createData.create_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "smth_base = \"D:informconnection\\\\\"\n",
    "base_tile_dir = smth_base + 'train\\\\*'\n",
    "df = pd.DataFrame({'path': glob(os.path.join(base_tile_dir, '*.jpg'))})\n",
    "df['target'] = df['path'].apply(lambda x: x.split('\\\\')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2091"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "def external_scale(x):\n",
    "    image = Image.open(x)\n",
    "    img = image.resize((200, 200), PIL.Image.ANTIALIAS)\n",
    "    img.save(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "5       None\n",
       "6       None\n",
       "7       None\n",
       "8       None\n",
       "9       None\n",
       "10      None\n",
       "11      None\n",
       "12      None\n",
       "13      None\n",
       "14      None\n",
       "15      None\n",
       "16      None\n",
       "17      None\n",
       "18      None\n",
       "19      None\n",
       "20      None\n",
       "21      None\n",
       "22      None\n",
       "23      None\n",
       "24      None\n",
       "25      None\n",
       "26      None\n",
       "27      None\n",
       "28      None\n",
       "29      None\n",
       "        ... \n",
       "2061    None\n",
       "2062    None\n",
       "2063    None\n",
       "2064    None\n",
       "2065    None\n",
       "2066    None\n",
       "2067    None\n",
       "2068    None\n",
       "2069    None\n",
       "2070    None\n",
       "2071    None\n",
       "2072    None\n",
       "2073    None\n",
       "2074    None\n",
       "2075    None\n",
       "2076    None\n",
       "2077    None\n",
       "2078    None\n",
       "2079    None\n",
       "2080    None\n",
       "2081    None\n",
       "2082    None\n",
       "2083    None\n",
       "2084    None\n",
       "2085    None\n",
       "2086    None\n",
       "2087    None\n",
       "2088    None\n",
       "2089    None\n",
       "2090    None\n",
       "Name: path, Length: 2091, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "df['path'].apply(lambda x: external_scale(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 198, 198, 16)      448       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 196, 196, 16)      2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 196, 196, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 196, 196, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 98, 98, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 98, 98, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 96, 96, 32)        4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 94, 94, 32)        9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 94, 94, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 94, 94, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 70688)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                4524032   \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 4,541,444\n",
      "Trainable params: 4,541,156\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras_radam import RAdam\n",
    "\n",
    "kernel_size = (3,3)\n",
    "pool_size= (2,2)\n",
    "first_filters = 16\n",
    "second_filters = 32\n",
    "\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (200, 200, 3)))\n",
    "model.add(Conv2D(first_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size)) \n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(dropout_dense))\n",
    "model.add(Dense(4, activation = \"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(RAdam(0.01), loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2091 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "CLASS_NAMES = ['exp', 'tan', 'sin_cos', 'linear']\n",
    "STEPS_PER_EPOCH = np.ceil(len(df)/BATCH_SIZE)\n",
    "train_data_gen = image_generator.flow_from_directory(directory=\"D:informconnection\\\\train\",\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(200, 200),\n",
    "                                                     classes = CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzhal\\Anaconda3\\envs\\neural_network\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_batch(image_batch, label_batch):\n",
    "  plt.figure(figsize=(10,10))\n",
    "  for n in range(25):\n",
    "      ax = plt.subplot(5,5,n+1)\n",
    "      plt.imshow(image_batch[n])\n",
    "#       plt.title(CLASS_NAMES[label_batch[n]])\n",
    "      plt.axis('off')\n",
    "image_batch, label_batch = next(train_data_gen)\n",
    "show_batch(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2eb6ef2c0b8>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dzhal\\Anaconda3\\envs\\neural_network\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 43s 648ms/step - loss: 0.1658 - acc: 0.9377\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 12s 189ms/step - loss: 0.0177 - acc: 0.9979\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 13s 190ms/step - loss: 0.0080 - acc: 0.9998\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 12s 188ms/step - loss: 0.0049 - acc: 0.9998\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 12s 188ms/step - loss: 0.0128 - acc: 0.9974\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 12s 189ms/step - loss: 0.0047 - acc: 0.9991\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 12s 188ms/step - loss: 0.0032 - acc: 0.9996\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 13s 190ms/step - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 12s 189ms/step - loss: 9.9836e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 12s 181ms/step - loss: 8.1027e-04 - acc: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2eb6de22470>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_data_gen,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
